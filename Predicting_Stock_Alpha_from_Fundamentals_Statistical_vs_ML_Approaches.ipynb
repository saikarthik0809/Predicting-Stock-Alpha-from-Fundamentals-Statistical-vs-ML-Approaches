{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        },
        "id": "W_grjjnWW_pi",
        "outputId": "8b1ed9fd-83e2-4159-b507-4fcc3ccb74dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Universe size: 20\n",
            "['AAPL', 'MSFT', 'AMZN', 'GOOGL', 'META', 'TSLA', 'NVDA', 'AVGO', 'AMD', 'INTC', 'QCOM', 'TXN', 'MU', 'CRM', 'ORCL', 'ADBE', 'IBM', 'HPQ', 'DELL', 'CSCO']\n",
            "Downloading AAPL...\n",
            "Downloading MSFT...\n",
            "Downloading AMZN...\n",
            "Downloading GOOGL...\n",
            "Downloading META...\n",
            "Downloading TSLA...\n",
            "Downloading NVDA...\n",
            "Downloading AVGO...\n",
            "Downloading AMD...\n",
            "Downloading INTC...\n",
            "Downloading QCOM...\n",
            "Downloading TXN...\n",
            "Downloading MU...\n",
            "Downloading CRM...\n",
            "Downloading ORCL...\n",
            "Downloading ADBE...\n",
            "Downloading IBM...\n",
            "Downloading HPQ...\n",
            "Downloading DELL...\n",
            "Downloading CSCO...\n",
            "Price cache complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3799846647.py:64: FutureWarning: 'Q' is deprecated and will be removed in a future version, please use 'QE' instead.\n",
            "  px_q = px.resample('Q').last()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'to_frame'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3799846647.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m             .set_index('Date').sort_index()['Adj Close'])\n\u001b[1;32m     64\u001b[0m     \u001b[0mpx_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mqret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qret'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mqret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mqret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'quarter_end'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6301\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'to_frame'"
          ]
        }
      ],
      "source": [
        "# ===== 0) Install dependencies =====\n",
        "!pip -q install yfinance fastparquet\n",
        "\n",
        "# ===== 1) Mount Google Drive =====\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ===== 2) Folder structure =====\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "PRICES_DIR   = PROJECT_ROOT / \"data\" / \"prices\"\n",
        "QRET_DIR     = PROJECT_ROOT / \"data\" / \"qreturns\"\n",
        "PROJECT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "PRICES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "QRET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ===== 3) Fixed Tech 20 tickers =====\n",
        "tickers = [\n",
        "    \"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\"NVDA\",\n",
        "    \"AVGO\",\"AMD\",\"INTC\",\"QCOM\",\"TXN\",\"MU\",\n",
        "    \"CRM\",\"ORCL\",\"ADBE\",\n",
        "    \"IBM\",\"HPQ\",\"DELL\",\"CSCO\"\n",
        "]\n",
        "# Adjust for Yahoo convention\n",
        "tickers = [t.replace(\".\", \"-\") for t in tickers]\n",
        "print(\"Universe size:\", len(tickers))\n",
        "print(tickers)\n",
        "\n",
        "# ===== 4) Download and cache daily prices =====\n",
        "import yfinance as yf\n",
        "import pandas as pd, time, sys\n",
        "\n",
        "start, end = \"2010-01-01\", \"2024-01-01\"\n",
        "\n",
        "for t in tickers:\n",
        "    fpath = PRICES_DIR/f\"{t}.parquet\"\n",
        "    if fpath.exists():\n",
        "        continue\n",
        "    try:\n",
        "        print(f\"Downloading {t}...\")\n",
        "        df = yf.download(t, start=start, end=end, auto_adjust=False, progress=False).reset_index()\n",
        "        # Ensure Adj Close column exists\n",
        "        if 'Adj Close' not in df.columns:\n",
        "            df = yf.download(t, start=start, end=end, auto_adjust=True, progress=False).reset_index()\n",
        "            df = df.rename(columns={'Close':'Adj Close'})\n",
        "        df.to_parquet(fpath)\n",
        "        time.sleep(1)  # throttle\n",
        "    except Exception as e:\n",
        "        print(f\"Failed {t}: {e}\", file=sys.stderr)\n",
        "\n",
        "print(\"Price cache complete.\")\n",
        "\n",
        "# ===== 5) Convert to quarterly returns =====\n",
        "for t in tickers:\n",
        "    fp = PRICES_DIR/f\"{t}.parquet\"\n",
        "    if not fp.exists():\n",
        "        continue\n",
        "    df = pd.read_parquet(fp)\n",
        "    if 'Date' not in df.columns or 'Adj Close' not in df.columns:\n",
        "        continue\n",
        "    px = (df[['Date','Adj Close']].dropna()\n",
        "            .assign(Date=lambda d: pd.to_datetime(d['Date']))\n",
        "            .set_index('Date').sort_index()['Adj Close'])\n",
        "    px_q = px.resample('Q').last()\n",
        "    qret = px_q.pct_change().dropna().to_frame('qret').reset_index()\n",
        "    qret['ticker'] = t\n",
        "    qret.rename(columns={'Date':'quarter_end'}, inplace=True)\n",
        "    qret.to_parquet(QRET_DIR/f\"{t}.parquet\")\n",
        "\n",
        "# ===== 6) Merge into one quarterly panel =====\n",
        "frames = []\n",
        "for t in tickers:\n",
        "    fp = QRET_DIR/f\"{t}.parquet\"\n",
        "    if fp.exists():\n",
        "        frames.append(pd.read_parquet(fp))\n",
        "if frames:\n",
        "    panel = pd.concat(frames, ignore_index=True)\n",
        "    panel.to_parquet(PROJECT_ROOT/'data'/'tech20_quarterly_returns.parquet')\n",
        "    print(\"Saved panel:\", PROJECT_ROOT/'data'/'tech20_quarterly_returns.parquet')\n",
        "    print(panel.head())\n",
        "else:\n",
        "    print(\"No quarterly returns generated.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Convert cached daily prices to quarterly returns =====\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "PRICES_DIR   = PROJECT_ROOT / \"data\" / \"prices\"\n",
        "QRET_DIR     = PROJECT_ROOT / \"data\" / \"qreturns\"\n",
        "QRET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "tickers = [\n",
        "    \"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\"NVDA\",\n",
        "    \"AVGO\",\"AMD\",\"INTC\",\"QCOM\",\"TXN\",\"MU\",\n",
        "    \"CRM\",\"ORCL\",\"ADBE\",\"IBM\",\"HPQ\",\"DELL\",\"CSCO\"\n",
        "]\n",
        "\n",
        "for t in tickers:\n",
        "    fp = PRICES_DIR/f\"{t}.parquet\"\n",
        "    if not fp.exists():\n",
        "        continue\n",
        "    df = pd.read_parquet(fp)\n",
        "    if 'Date' not in df.columns or 'Adj Close' not in df.columns:\n",
        "        continue\n",
        "\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    df = df.sort_values('Date')\n",
        "    px = df.set_index('Date')['Adj Close'].dropna()\n",
        "\n",
        "    # Quarterly frequency with quarter-end\n",
        "    px_q = px.resample('QE').last()\n",
        "    qret = px_q.pct_change().dropna().reset_index()\n",
        "    qret.columns = ['quarter_end', 'qret']\n",
        "    qret['ticker'] = t\n",
        "\n",
        "    qret.to_parquet(QRET_DIR/f\"{t}.parquet\")\n",
        "\n",
        "# ===== Merge into one panel =====\n",
        "frames = []\n",
        "for t in tickers:\n",
        "    fp = QRET_DIR/f\"{t}.parquet\"\n",
        "    if fp.exists():\n",
        "        frames.append(pd.read_parquet(fp))\n",
        "\n",
        "if frames:\n",
        "    panel = pd.concat(frames, ignore_index=True)\n",
        "    panel.to_parquet(PROJECT_ROOT/'data'/'tech20_quarterly_returns.parquet')\n",
        "    print(\"Saved:\", PROJECT_ROOT/'data'/'tech20_quarterly_returns.parquet')\n",
        "    print(panel.head())\n",
        "else:\n",
        "    print(\"No quarterly returns generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEPEyo9Rj-8i",
        "outputId": "ede1d4b7-6559-4782-d190-82708e1d8172"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/alpha_project/data/tech20_quarterly_returns.parquet\n",
            "  quarter_end      qret ticker\n",
            "0  2010-06-30  0.070340   AAPL\n",
            "1  2010-09-30  0.128096   AAPL\n",
            "2  2010-12-31  0.136776   AAPL\n",
            "3  2011-03-31  0.080450   AAPL\n",
            "4  2011-06-30 -0.036843   AAPL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Load datasets =====\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "\n",
        "indicators = pd.read_csv(\"/content/indicators_by_company.csv\")\n",
        "companies  = pd.read_csv(\"/content/companies.csv\")\n",
        "\n",
        "# ===== Tech 20 tickers and stricter patterns (corrected META, HPQ) =====\n",
        "ticker_map = {\n",
        "    \"AAPL\": \"^APPLE INC\",\n",
        "    \"MSFT\": \"^MICROSOFT\",\n",
        "    \"AMZN\": \"^AMAZON\",\n",
        "    \"GOOGL\": \"ALPHABET|GOOGLE\",\n",
        "    \"META\": \"FACEBOOK|META PLATFORMS\",\n",
        "    \"TSLA\": \"^TESLA\",\n",
        "    \"NVDA\": \"^NVIDIA\",\n",
        "    \"AVGO\": \"^BROADCOM\",\n",
        "    \"AMD\": \"^ADVANCED MICRO\",\n",
        "    \"INTC\": \"^INTEL CORP\",\n",
        "    \"QCOM\": \"^QUALCOMM\",\n",
        "    \"TXN\": \"^TEXAS INSTRUMENTS\",\n",
        "    \"MU\": \"^MICRON\",\n",
        "    \"CRM\": \"^SALESFORCE\",\n",
        "    \"ORCL\": \"^ORACLE\",\n",
        "    \"ADBE\": \"^ADOBE\",\n",
        "    \"IBM\": \"^INTERNATIONAL BUSINESS MACHINES\",\n",
        "    \"HPQ\": \"^HP INC\",       # force HP Inc (not Hewlett Packard Enterprise)\n",
        "    \"DELL\": \"^DELL\",\n",
        "    \"CSCO\": \"^CISCO SYSTEMS\"\n",
        "}\n",
        "\n",
        "# ===== Step 1: Match tickers to company_id =====\n",
        "companies['name_upper'] = companies['name_latest'].str.upper()\n",
        "\n",
        "matches = []\n",
        "for t, pattern in ticker_map.items():\n",
        "    hit = companies[companies['name_upper'].str.contains(pattern, regex=True, na=False)]\n",
        "    if not hit.empty:\n",
        "        # Filter out junk like REIT, TRUST, BANK\n",
        "        hit = hit[~hit['name_upper'].str.contains(\"TRUST|REIT|BANK\", na=False)]\n",
        "        if not hit.empty:\n",
        "            row = hit.iloc[0]  # take first valid match\n",
        "            matches.append({\"ticker\": t, \"company_id\": row['company_id'], \"name\": row['name_latest']})\n",
        "        else:\n",
        "            print(\"Filtered out junk for\", t)\n",
        "    else:\n",
        "        print(\"No match for\", t)\n",
        "\n",
        "mapping_df = pd.DataFrame(matches)\n",
        "print(\"Ticker mapping (cleaned):\")\n",
        "print(mapping_df)\n",
        "\n",
        "# ===== Step 2: Filter fundamentals for tech company_ids =====\n",
        "tech_ids = mapping_df['company_id'].tolist()\n",
        "funds = indicators[indicators['company_id'].isin(tech_ids)].copy()\n",
        "\n",
        "# Melt to tidy format\n",
        "value_cols = [c for c in funds.columns if c.isdigit()]\n",
        "funds_tidy = funds.melt(id_vars=['company_id','indicator_id'],\n",
        "                        value_vars=value_cols,\n",
        "                        var_name='year',\n",
        "                        value_name='value')\n",
        "funds_tidy['year'] = funds_tidy['year'].astype(int)\n",
        "\n",
        "# Pivot indicators to wide format\n",
        "funds_wide = funds_tidy.pivot_table(index=['company_id','year'],\n",
        "                                    columns='indicator_id',\n",
        "                                    values='value')\n",
        "funds_wide = funds_wide.reset_index()\n",
        "\n",
        "# ===== Step 3: Attach tickers =====\n",
        "funds_wide = funds_wide.merge(mapping_df[['ticker','company_id']],\n",
        "                              on='company_id', how='inner')\n",
        "\n",
        "print(\"Fundamentals panel shape:\", funds_wide.shape)\n",
        "print(funds_wide[['ticker','year']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uDttzsRkObQ",
        "outputId": "8aade4dd-914d-414a-e086-d5ca071358ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ticker mapping (cleaned):\n",
            "   ticker  company_id                                  name\n",
            "0    AAPL      320193                             Apple Inc\n",
            "1    MSFT      789019                        Microsoft Corp\n",
            "2    AMZN     1018724                        Amazon COM Inc\n",
            "3   GOOGL     1288776                           Google Inc.\n",
            "4    META     1326801                          Facebook Inc\n",
            "5    TSLA     1318605                      Tesla Motors Inc\n",
            "6    NVDA     1045810                           Nvidia Corp\n",
            "7    AVGO     1054374                         Broadcom Corp\n",
            "8     AMD        2488            Advanced Micro Devices Inc\n",
            "9    INTC       50863                            Intel Corp\n",
            "10   QCOM      804328                       Qualcomm Inc/De\n",
            "11    TXN       97476                 Texas Instruments Inc\n",
            "12     MU      723125                 Micron Technology Inc\n",
            "13    CRM     1108524                    Salesforce COM Inc\n",
            "14   ORCL     1341439                           Oracle Corp\n",
            "15   ADBE      796343                     Adobe Systems Inc\n",
            "16    IBM       51143  International Business Machines Corp\n",
            "17    HPQ       47217                                HP Inc\n",
            "18   DELL      826083                              Dell Inc\n",
            "19   CSCO      858877                   Cisco Systems, Inc.\n",
            "Fundamentals panel shape: (100, 1847)\n",
            "  ticker  year\n",
            "0    AMD  2011\n",
            "1    AMD  2012\n",
            "2    AMD  2013\n",
            "3    AMD  2014\n",
            "4    AMD  2015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Scan indicator IDs by keyword and save to CSV =====\n",
        "import pandas as pd\n",
        "\n",
        "indicators = pd.read_csv(\"/content/indicators_by_company.csv\")\n",
        "\n",
        "unique_ids = indicators['indicator_id'].unique().tolist()\n",
        "\n",
        "keywords = [\"NETINCOME\", \"ASSET\", \"LIABILIT\", \"EQUITY\",\n",
        "            \"REVENUE\", \"SALES\", \"GROSSPROFIT\", \"SHARES\"]\n",
        "\n",
        "rows = []\n",
        "for kw in keywords:\n",
        "    hits = [x for x in unique_ids if kw in x.upper()]\n",
        "    for h in hits:\n",
        "        rows.append({\"keyword\": kw, \"indicator_id\": h})\n",
        "\n",
        "ref_df = pd.DataFrame(rows)\n",
        "\n",
        "# Save reference file\n",
        "outpath = \"/content/indicator_reference.csv\"\n",
        "ref_df.to_csv(outpath, index=False)\n",
        "\n",
        "print(\"Saved reference file with matches:\", outpath)\n",
        "print(ref_df.groupby(\"keyword\").size())\n",
        "print(ref_df.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ7EfoqIoHzr",
        "outputId": "efd48c74-445f-402d-d5e5-b798c4c63a6f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved reference file with matches: /content/indicator_reference.csv\n",
            "keyword\n",
            "ASSET          928\n",
            "EQUITY         289\n",
            "GROSSPROFIT      5\n",
            "LIABILIT       715\n",
            "NETINCOME       78\n",
            "REVENUE        259\n",
            "SALES          258\n",
            "SHARES         210\n",
            "dtype: int64\n",
            "      keyword                                       indicator_id\n",
            "0   NETINCOME                                      NetIncomeLoss\n",
            "1   NETINCOME    NetIncomeLossAvailableToCommonStockholdersBasic\n",
            "2   NETINCOME  AdjustmentsNoncashItemsToReconcileNetIncomeLos...\n",
            "3   NETINCOME  AdjustmentsToReconcileNetIncomeLossToCashProvi...\n",
            "4   NETINCOME  EquityMethodInvestmentSummarizedFinancialInfor...\n",
            "5   NETINCOME  NetIncomeLossAttributableToNoncontrollingInterest\n",
            "6   NETINCOME  NetIncomeLossAvailableToCommonStockholdersDiluted\n",
            "7   NETINCOME  OtherComprehensiveIncomeLossReclassificationAd...\n",
            "8   NETINCOME  OtherComprehensiveIncomeLossReclassificationAd...\n",
            "9   NETINCOME  OtherComprehensiveIncomeReclassificationAdjust...\n",
            "10  NETINCOME  OtherComprehensiveIncomeReclassificationAdjust...\n",
            "11  NETINCOME  OtherThanTemporaryImpairmentLossesInvestmentsR...\n",
            "12  NETINCOME  NetIncomeLossAttributableToRedeemableNoncontro...\n",
            "13  NETINCOME  NetIncomeLossIncludingPortionAttributableToNon...\n",
            "14  NETINCOME          BusinessAcquisitionsProFormaNetIncomeLoss\n",
            "15  NETINCOME  OtherComprehensiveIncomeLossReclassificationAd...\n",
            "16  NETINCOME  OtherComprehensiveIncomeReclassificationAdjust...\n",
            "17  NETINCOME  OtherComprehensiveIncomeLossReclassificationAd...\n",
            "18  NETINCOME  OtherComprehensiveIncomeLossReclassificationAd...\n",
            "19  NETINCOME  OtherComprehensiveIncomeReclassificationAdjust...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 0) Imports =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "\n",
        "# ===== 1) Load fundamentals =====\n",
        "indicators = pd.read_csv(\"/content/indicators_by_company.csv\")\n",
        "\n",
        "# Keep only relevant indicator IDs\n",
        "chosen_indicators = [\n",
        "    \"NetIncomeLoss\",\n",
        "    \"Assets\",\n",
        "    \"Liabilities\",\n",
        "    \"StockholdersEquity\",\n",
        "    \"StockholdersEquityIncludingPortionAttributableToNoncontrollingInterest\",\n",
        "    \"Revenues\",\n",
        "    \"SalesRevenueNet\",\n",
        "    \"GrossProfit\",\n",
        "    \"CommonStockSharesOutstanding\"\n",
        "]\n",
        "\n",
        "funds = indicators[indicators['indicator_id'].isin(chosen_indicators)].copy()\n",
        "\n",
        "# ===== 2) Reshape =====\n",
        "value_cols = [c for c in funds.columns if c.isdigit()]\n",
        "funds_tidy = funds.melt(id_vars=['company_id','indicator_id'],\n",
        "                        value_vars=value_cols,\n",
        "                        var_name='year',\n",
        "                        value_name='value')\n",
        "funds_tidy['year'] = funds_tidy['year'].astype(int)\n",
        "\n",
        "funds_wide = funds_tidy.pivot_table(index=['company_id','year'],\n",
        "                                    columns='indicator_id',\n",
        "                                    values='value',\n",
        "                                    aggfunc='first').reset_index()\n",
        "\n",
        "# ===== 3) Attach tickers (mapping from earlier) =====\n",
        "mapping_df = pd.DataFrame({\n",
        "    \"ticker\": [\"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"META\",\"TSLA\",\"NVDA\",\"AVGO\",\"AMD\",\"INTC\",\n",
        "               \"QCOM\",\"TXN\",\"MU\",\"CRM\",\"ORCL\",\"ADBE\",\"IBM\",\"HPQ\",\"DELL\",\"CSCO\"],\n",
        "    \"company_id\": [320193,789019,1018724,1288776,1326801,1318605,1045810,1054374,2488,50863,\n",
        "                   804328,97476,723125,1108524,1341439,796343,51143,47217,826083,858877]\n",
        "})\n",
        "funds_wide = funds_wide.merge(mapping_df, on=\"company_id\", how=\"inner\")\n",
        "\n",
        "# ===== 4) Load quarterly returns =====\n",
        "returns = pd.read_parquet(PROJECT_ROOT/'data'/'tech20_quarterly_returns.parquet')\n",
        "returns['year'] = pd.to_datetime(returns['quarter_end']).dt.year\n",
        "\n",
        "# ===== 5) Merge annual fundamentals with quarterly returns =====\n",
        "panel = returns.merge(funds_wide, on=['ticker','year'], how='left')\n",
        "\n",
        "# ===== 6) Compute ratios =====\n",
        "# Equity: pick whichever of the two equity columns is non-null\n",
        "panel['Equity_clean'] = panel[['StockholdersEquity',\n",
        "                               'StockholdersEquityIncludingPortionAttributableToNoncontrollingInterest']].bfill(axis=1).iloc[:,0]\n",
        "\n",
        "panel['Revenue_clean'] = panel[['Revenues','SalesRevenueNet']].bfill(axis=1).iloc[:,0]\n",
        "\n",
        "panel['ROE'] = panel['NetIncomeLoss'] / panel['Equity_clean']\n",
        "panel['ROA'] = panel['NetIncomeLoss'] / panel['Assets']\n",
        "panel['Leverage'] = panel['Liabilities'] / panel['Assets']\n",
        "panel['ProfitMargin'] = panel['NetIncomeLoss'] / panel['Revenue_clean']\n",
        "panel['GrossMargin'] = panel['GrossProfit'] / panel['Revenue_clean']\n",
        "\n",
        "# ===== 7) Save final dataset =====\n",
        "final_cols = ['ticker','quarter_end','qret','ROE','ROA','Leverage','ProfitMargin','GrossMargin']\n",
        "panel_final = panel[final_cols]\n",
        "\n",
        "outpath = PROJECT_ROOT/'data'/'tech20_fundamentals_returns.csv'\n",
        "panel_final.to_csv(outpath, index=False)\n",
        "\n",
        "print(\"Saved dataset:\", outpath)\n",
        "print(panel_final.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-LIy7X9p0uA",
        "outputId": "b85d87eb-faf1-4da9-d226-5127a10d52b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved dataset: /content/drive/MyDrive/alpha_project/data/tech20_fundamentals_returns.csv\n",
            "  ticker quarter_end      qret       ROE       ROA  Leverage  ProfitMargin  \\\n",
            "0   AAPL  2010-06-30  0.070340       NaN       NaN       NaN           NaN   \n",
            "1   AAPL  2010-09-30  0.128096       NaN       NaN       NaN           NaN   \n",
            "2   AAPL  2010-12-31  0.136776       NaN       NaN       NaN           NaN   \n",
            "3   AAPL  2011-03-31  0.080450  0.338341  0.222753  0.341632      0.239466   \n",
            "4   AAPL  2011-06-30 -0.036843  0.338341  0.222753  0.341632      0.239466   \n",
            "\n",
            "   GrossMargin  \n",
            "0          NaN  \n",
            "1          NaN  \n",
            "2          NaN  \n",
            "3     0.404789  \n",
            "4     0.404789  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Preprocess fundamentals + returns for ML =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "\n",
        "df = pd.read_csv(PROJECT_ROOT/'data'/'tech20_fundamentals_returns.csv')\n",
        "\n",
        "# 1. Drop rows with missing qret or all-NaN predictors\n",
        "predictors = ['ROE','ROA','Leverage','ProfitMargin','GrossMargin']\n",
        "df = df.dropna(subset=['qret'])\n",
        "\n",
        "# 2. Replace inf with NaN\n",
        "df[predictors] = df[predictors].replace([np.inf,-np.inf], np.nan)\n",
        "\n",
        "# 3. Drop rows with any missing predictors\n",
        "df = df.dropna(subset=predictors)\n",
        "\n",
        "# 4. Optional: winsorize (clip) to reduce effect of outliers\n",
        "for col in predictors:\n",
        "    lower, upper = df[col].quantile([0.01, 0.99])\n",
        "    df[col] = df[col].clip(lower, upper)\n",
        "\n",
        "# 5. Standardize predictors (z-score)\n",
        "for col in predictors:\n",
        "    mean, std = df[col].mean(), df[col].std()\n",
        "    df[col] = (df[col] - mean) / std\n",
        "\n",
        "# 6. Save final ML-ready dataset\n",
        "outpath = PROJECT_ROOT/'data'/'tech20_ml_ready.csv'\n",
        "df.to_csv(outpath, index=False)\n",
        "\n",
        "print(\"Saved ML-ready dataset:\", outpath)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aJWLJIcqBcM",
        "outputId": "d781da0c-5321-4d77-e15b-315999c2152e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved ML-ready dataset: /content/drive/MyDrive/alpha_project/data/tech20_ml_ready.csv\n",
            "  ticker quarter_end      qret       ROE       ROA  Leverage  ProfitMargin  \\\n",
            "3   AAPL  2011-03-31  0.080450  0.571551  1.349512 -1.137064      0.605392   \n",
            "4   AAPL  2011-06-30 -0.036843  0.571551  1.349512 -1.137064      0.605392   \n",
            "5   AAPL  2011-09-30  0.135996  0.571551  1.349512 -1.137064      0.605392   \n",
            "6   AAPL  2011-12-31  0.062100  0.571551  1.349512 -1.137064      0.605392   \n",
            "7   AAPL  2012-03-31  0.480370  0.597208  1.465889 -1.229378      0.699525   \n",
            "\n",
            "   GrossMargin  \n",
            "3    -0.636061  \n",
            "4    -0.636061  \n",
            "5    -0.636061  \n",
            "6    -0.636061  \n",
            "7    -0.486774  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "T_JsoDWrq1v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Load ML-ready dataset =====\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "\n",
        "# Directly load the cleaned file\n",
        "df = pd.read_csv(PROJECT_ROOT/'data'/'tech20_ml_ready.csv')\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(df.head())\n",
        "\n",
        "# Define target and predictors\n",
        "target = \"qret\"\n",
        "predictors = ['ROE','ROA','Leverage','ProfitMargin','GrossMargin']\n",
        "X = df[predictors]\n",
        "y = df[target]\n",
        "\n",
        "print(\"Features ready for modeling:\")\n",
        "print(predictors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frNn-XaPqmv1",
        "outputId": "78b13f6c-18b8-4495-834a-02a75f8a2f65"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (170, 8)\n",
            "  ticker quarter_end      qret       ROE       ROA  Leverage  ProfitMargin  \\\n",
            "0   AAPL  2011-03-31  0.080450  0.571551  1.349512 -1.137064      0.605392   \n",
            "1   AAPL  2011-06-30 -0.036843  0.571551  1.349512 -1.137064      0.605392   \n",
            "2   AAPL  2011-09-30  0.135996  0.571551  1.349512 -1.137064      0.605392   \n",
            "3   AAPL  2011-12-31  0.062100  0.571551  1.349512 -1.137064      0.605392   \n",
            "4   AAPL  2012-03-31  0.480370  0.597208  1.465889 -1.229378      0.699525   \n",
            "\n",
            "   GrossMargin  \n",
            "0    -0.636061  \n",
            "1    -0.636061  \n",
            "2    -0.636061  \n",
            "3    -0.636061  \n",
            "4    -0.486774  \n",
            "Features ready for modeling:\n",
            "['ROE', 'ROA', 'Leverage', 'ProfitMargin', 'GrossMargin']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== OLS Backtest (expanding window with forward-fill) =====\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "df = pd.read_csv(PROJECT_ROOT/'data'/'tech20_ml_ready.csv')\n",
        "\n",
        "factors = ['ROE','ROA','Leverage','ProfitMargin','GrossMargin']\n",
        "target = 'qret'\n",
        "df['quarter_end'] = pd.to_datetime(df['quarter_end'])\n",
        "df = df.sort_values(['quarter_end','ticker'])\n",
        "\n",
        "# Forward-fill predictors by ticker to avoid NaNs\n",
        "df[factors] = df.groupby('ticker')[factors].ffill()\n",
        "\n",
        "start_test = pd.Timestamp(\"2014-01-01\")\n",
        "results = []\n",
        "\n",
        "for q in sorted(df['quarter_end'].unique()):\n",
        "    if q < start_test:\n",
        "        continue\n",
        "\n",
        "    # expanding training set: all prior quarters\n",
        "    train = df[df['quarter_end'] < q]\n",
        "    test  = df[df['quarter_end'] == q]\n",
        "    if train.empty or test.empty:\n",
        "        continue\n",
        "\n",
        "    # Ensure no NaNs in predictors\n",
        "    X_train = sm.add_constant(train[factors].dropna())\n",
        "    y_train = train.loc[X_train.index, target]\n",
        "\n",
        "    if len(X_train) <= len(factors):  # skip if too few obs\n",
        "        continue\n",
        "\n",
        "    model = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "    # Predict current quarter\n",
        "    X_test = sm.add_constant(test[factors].fillna(0))  # fill if still NaN\n",
        "    test = test.copy()\n",
        "    test['pred'] = model.predict(X_test)\n",
        "\n",
        "    # Long–short portfolio\n",
        "    top = test.nlargest(5, 'pred')\n",
        "    bottom = test.nsmallest(5, 'pred')\n",
        "    long_ret = top[target].mean()\n",
        "    short_ret = bottom[target].mean()\n",
        "    ls_ret = long_ret - short_ret\n",
        "\n",
        "    results.append({\n",
        "        'quarter_end': q,\n",
        "        'long_ret': long_ret,\n",
        "        'short_ret': short_ret,\n",
        "        'ls_ret': ls_ret\n",
        "    })\n",
        "\n",
        "# Build backtest dataframe\n",
        "if results:\n",
        "    ols_bt = pd.DataFrame(results).set_index('quarter_end')\n",
        "    ols_bt['cum_ls'] = (1 + ols_bt['ls_ret']).cumprod()\n",
        "\n",
        "    print(\"Backtest results (first rows):\")\n",
        "    print(ols_bt.head())\n",
        "    print(\"\\nBacktest results (last rows):\")\n",
        "    print(ols_bt.tail())\n",
        "    print(\"\\nFinal cumulative long-short return:\", ols_bt['cum_ls'].iloc[-1])\n",
        "\n",
        "    # Save results\n",
        "    outpath = PROJECT_ROOT/'data'/'ols_backtest_expanding_ffill.csv'\n",
        "    ols_bt.to_csv(outpath)\n",
        "    print(\"Saved OLS backtest:\", outpath)\n",
        "else:\n",
        "    print(\"No backtest results. Try an earlier start_test date or adjust NaN handling.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohcs1bTdqpRB",
        "outputId": "5a76a7e6-c618-439a-d197-21c22011b997"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backtest results (first rows):\n",
            "             long_ret  short_ret    ls_ret    cum_ls\n",
            "quarter_end                                         \n",
            "2014-03-31   0.114860   0.064994  0.049866  1.049866\n",
            "2014-06-30   0.160972   0.056072  0.104900  1.159997\n",
            "2014-09-30   0.049888   0.019615  0.030273  1.195114\n",
            "2014-12-31   0.015580   0.064866 -0.049286  1.136211\n",
            "2015-03-31  -0.047312   0.054334 -0.101646  1.020720\n",
            "\n",
            "Backtest results (last rows):\n",
            "             long_ret  short_ret    ls_ret    cum_ls\n",
            "quarter_end                                         \n",
            "2014-12-31   0.015580   0.064866 -0.049286  1.136211\n",
            "2015-03-31  -0.047312   0.054334 -0.101646  1.020720\n",
            "2015-06-30   0.052575   0.001356  0.051219  1.073000\n",
            "2015-09-30  -0.077866   0.034844 -0.112710  0.952062\n",
            "2015-12-31   0.052204   0.154204 -0.102000  0.854952\n",
            "\n",
            "Final cumulative long-short return: 0.8549518038383018\n",
            "Saved OLS backtest: /content/drive/MyDrive/alpha_project/data/ols_backtest_expanding_ffill.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Block 2: ML-style Linear Regression with Backtesting =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "df = pd.read_csv(PROJECT_ROOT/'data'/'tech20_ml_ready.csv')\n",
        "\n",
        "# Features and target\n",
        "factors = ['ROE','ROA','Leverage','ProfitMargin','GrossMargin']\n",
        "target = 'qret'\n",
        "df['quarter_end'] = pd.to_datetime(df['quarter_end'])\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values(['quarter_end','ticker'])\n",
        "\n",
        "# Backtest parameters\n",
        "start_test = pd.Timestamp(\"2014-01-01\")  # start test earlier to ensure coverage\n",
        "results = []\n",
        "\n",
        "for q in sorted(df['quarter_end'].unique()):\n",
        "    if q < start_test:\n",
        "        continue\n",
        "    train = df[df['quarter_end'] < q]\n",
        "    test  = df[df['quarter_end'] == q]\n",
        "    if train.empty or test.empty:\n",
        "        continue\n",
        "\n",
        "    X_train, y_train = train[factors], train[target]\n",
        "    X_test, y_test   = test[factors], test[target]\n",
        "\n",
        "    # Fit linear regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict current quarter returns\n",
        "    test = test.copy()\n",
        "    test['pred'] = model.predict(X_test)\n",
        "\n",
        "    # Long–short portfolio: top 5 vs bottom 5 predicted returns\n",
        "    top = test.nlargest(5, 'pred')\n",
        "    bottom = test.nsmallest(5, 'pred')\n",
        "    long_ret = top[target].mean()\n",
        "    short_ret = bottom[target].mean()\n",
        "    ls_ret = long_ret - short_ret\n",
        "\n",
        "    results.append({\n",
        "        'quarter_end': q,\n",
        "        'long_ret': long_ret,\n",
        "        'short_ret': short_ret,\n",
        "        'ls_ret': ls_ret\n",
        "    })\n",
        "\n",
        "# Build backtest dataframe\n",
        "if results:\n",
        "    bt = pd.DataFrame(results).set_index('quarter_end')\n",
        "    bt['cum_ls'] = (1 + bt['ls_ret']).cumprod()\n",
        "    print(\"Backtest results (first rows):\")\n",
        "    print(bt.head())\n",
        "    print(\"\\nFinal cumulative long-short return:\", bt['cum_ls'].iloc[-1])\n",
        "\n",
        "    # Save backtest results\n",
        "    outpath = PROJECT_ROOT/'data'/'linreg_backtest.csv'\n",
        "    bt.to_csv(outpath)\n",
        "    print(\"Saved backtest results:\", outpath)\n",
        "else:\n",
        "    print(\"No backtest results. Try setting an earlier start_test date.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLXeUyFDsZTs",
        "outputId": "590d1c9b-3ec3-4403-d048-30d603380186"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backtest results (first rows):\n",
            "             long_ret  short_ret    ls_ret    cum_ls\n",
            "quarter_end                                         \n",
            "2014-03-31   0.114860   0.064994  0.049866  1.049866\n",
            "2014-06-30   0.160972   0.056072  0.104900  1.159997\n",
            "2014-09-30   0.049888   0.019615  0.030273  1.195114\n",
            "2014-12-31   0.015580   0.064866 -0.049286  1.136211\n",
            "2015-03-31  -0.047312   0.054334 -0.101646  1.020720\n",
            "\n",
            "Final cumulative long-short return: 0.8549518038383018\n",
            "Saved backtest results: /content/drive/MyDrive/alpha_project/data/linreg_backtest.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Block 3: Gradient Boosting with Backtesting =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "df = pd.read_csv(PROJECT_ROOT/'data'/'tech20_ml_ready.csv')\n",
        "\n",
        "factors = ['ROE','ROA','Leverage','ProfitMargin','GrossMargin']\n",
        "target = 'qret'\n",
        "df['quarter_end'] = pd.to_datetime(df['quarter_end'])\n",
        "\n",
        "# Sort by time\n",
        "df = df.sort_values(['quarter_end','ticker'])\n",
        "\n",
        "# Backtest parameters\n",
        "start_test = pd.Timestamp(\"2014-01-01\")\n",
        "results = []\n",
        "\n",
        "for q in sorted(df['quarter_end'].unique()):\n",
        "    if q < start_test:\n",
        "        continue\n",
        "    train = df[df['quarter_end'] < q]\n",
        "    test  = df[df['quarter_end'] == q]\n",
        "    if train.empty or test.empty:\n",
        "        continue\n",
        "\n",
        "    X_train, y_train = train[factors], train[target]\n",
        "    X_test, y_test   = test[factors], test[target]\n",
        "\n",
        "    # Fit Gradient Boosting\n",
        "    model = GradientBoostingRegressor(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict current quarter returns\n",
        "    test = test.copy()\n",
        "    test['pred'] = model.predict(X_test)\n",
        "\n",
        "    # Long–short portfolio: top 5 vs bottom 5 predicted returns\n",
        "    top = test.nlargest(5, 'pred')\n",
        "    bottom = test.nsmallest(5, 'pred')\n",
        "    long_ret = top[target].mean()\n",
        "    short_ret = bottom[target].mean()\n",
        "    ls_ret = long_ret - short_ret\n",
        "\n",
        "    results.append({\n",
        "        'quarter_end': q,\n",
        "        'long_ret': long_ret,\n",
        "        'short_ret': short_ret,\n",
        "        'ls_ret': ls_ret\n",
        "    })\n",
        "\n",
        "# Build backtest dataframe\n",
        "if results:\n",
        "    bt = pd.DataFrame(results).set_index('quarter_end')\n",
        "    bt['cum_ls'] = (1 + bt['ls_ret']).cumprod()\n",
        "    print(\"Backtest results (first rows):\")\n",
        "    print(bt.head())\n",
        "    print(\"\\nFinal cumulative long-short return:\", bt['cum_ls'].iloc[-1])\n",
        "\n",
        "    # Save backtest results\n",
        "    outpath = PROJECT_ROOT/'data'/'gbr_backtest.csv'\n",
        "    bt.to_csv(outpath)\n",
        "    print(\"Saved backtest results:\", outpath)\n",
        "else:\n",
        "    print(\"No backtest results. Try an earlier start_test date.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjTyifacs-2s",
        "outputId": "260f7731-bd48-4f95-c887-552861787867"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backtest results (first rows):\n",
            "             long_ret  short_ret    ls_ret    cum_ls\n",
            "quarter_end                                         \n",
            "2014-03-31   0.124290   0.036701  0.087589  1.087589\n",
            "2014-06-30   0.137890   0.153308 -0.015419  1.070820\n",
            "2014-09-30   0.043020   0.046285 -0.003265  1.067324\n",
            "2014-12-31   0.019538   0.064866 -0.045328  1.018944\n",
            "2015-03-31   0.024339  -0.039197  0.063536  1.083684\n",
            "\n",
            "Final cumulative long-short return: 1.085520186965541\n",
            "Saved backtest results: /content/drive/MyDrive/alpha_project/data/gbr_backtest.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Summary Statistics Table =====\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/alpha_project\")\n",
        "\n",
        "# Load results\n",
        "linreg = pd.read_csv(PROJECT_ROOT/'data'/'linreg_backtest.csv')\n",
        "gbr    = pd.read_csv(PROJECT_ROOT/'data'/'gbr_backtest.csv')\n",
        "\n",
        "# Try loading OLS, but handle if missing\n",
        "try:\n",
        "    ols_bt = pd.read_csv(PROJECT_ROOT/'data'/'ols_backtest_expanding_ffill.csv')\n",
        "    ols_bt['model'] = 'OLS'\n",
        "except FileNotFoundError:\n",
        "    ols_bt = None\n",
        "\n",
        "linreg['model'] = 'Linear Regression'\n",
        "gbr['model'] = 'Gradient Boosting'\n",
        "\n",
        "# Collect\n",
        "dfs = []\n",
        "if ols_bt is not None and not ols_bt.empty:\n",
        "    dfs.append(ols_bt[['quarter_end','ls_ret','cum_ls','model']])\n",
        "dfs.append(linreg[['quarter_end','ls_ret','cum_ls','model']])\n",
        "dfs.append(gbr[['quarter_end','ls_ret','cum_ls','model']])\n",
        "\n",
        "all_bt = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Summary stats\n",
        "summary = []\n",
        "for model, grp in all_bt.groupby('model'):\n",
        "    final_ret = grp['cum_ls'].iloc[-1]\n",
        "    avg_q = grp['ls_ret'].mean()\n",
        "    vol_q = grp['ls_ret'].std()\n",
        "    sharpe = avg_q / vol_q if vol_q > 0 else np.nan\n",
        "    summary.append({\n",
        "        'Model': model,\n",
        "        'Final cumulative return': round(final_ret, 3),\n",
        "        'Avg quarterly return': round(avg_q, 3),\n",
        "        'Volatility': round(vol_q, 3),\n",
        "        'Sharpe ratio': round(sharpe, 2)\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary).set_index('Model')\n",
        "print(summary_df)\n",
        "\n",
        "# Save\n",
        "outpath = PROJECT_ROOT/'data'/'backtest_summary.csv'\n",
        "summary_df.to_csv(outpath)\n",
        "print(\"\\nSaved summary table:\", outpath)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB8SKpXiubCS",
        "outputId": "bca70d12-3187-48ab-8258-acf7d808ca33"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Final cumulative return  Avg quarterly return  Volatility  \\\n",
            "Model                                                                          \n",
            "Gradient Boosting                    1.086                 0.011       0.051   \n",
            "Linear Regression                    0.855                -0.016       0.085   \n",
            "OLS                                  0.855                -0.016       0.085   \n",
            "\n",
            "                   Sharpe ratio  \n",
            "Model                            \n",
            "Gradient Boosting          0.22  \n",
            "Linear Regression         -0.19  \n",
            "OLS                       -0.19  \n",
            "\n",
            "Saved summary table: /content/drive/MyDrive/alpha_project/data/backtest_summary.csv\n"
          ]
        }
      ]
    }
  ]
}